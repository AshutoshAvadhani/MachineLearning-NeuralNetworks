{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch import nn, optim\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data from MNIST using pytorch\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,)),\n",
    "])\n",
    "main_data_set = datasets.MNIST('~/.pytorch/MNIST/',download=True,train=True,transform = transform)\n",
    "# test_data = datasets.MNIST('~/.pytorch/MNIST/',download=True,train=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n"
     ]
    }
   ],
   "source": [
    "print(len(main_data_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train Test Validation Split\n",
    "train_size = int(0.7 * len(main_data_set))\n",
    "temp_size = len(main_data_set) - train_size\n",
    "train_dataset, temp_dataset = torch.utils.data.random_split(main_data_set, [train_size, temp_size])\n",
    "validation_size = int(0.5 * len(temp_dataset))\n",
    "test_size = len(temp_dataset) - validation_size\n",
    "validation_dataset, test_dataset = torch.utils.data.random_split(temp_dataset, [validation_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42000\n",
      "9000\n",
      "9000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset))\n",
    "print(len(validation_dataset))\n",
    "print(len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loader Creation\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset,batch_size =11,shuffle=True)\n",
    "validationloader = torch.utils.data.DataLoader(validation_dataset,batch_size = 11,shuffle=True)\n",
    "Testloader = torch.utils.data.DataLoader(test_dataset,batch_size=11,shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([11, 1, 28, 28])\n",
      "torch.Size([11])\n"
     ]
    }
   ],
   "source": [
    "#validation of Split dataset\n",
    "data_iter = iter(trainloader)\n",
    "images,labels = data_iter.next()\n",
    "print(images.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[0].numpy().squeeze(), cmap='gray_r');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure = plt.figure()\n",
    "num_of_images = 10\n",
    "for index in range(1, num_of_images + 1):\n",
    "    plt.subplot(6, 10, index)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(images[index].numpy().squeeze(), cmap='gray_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=784, out_features=30, bias=True)\n",
      "  (1): Sigmoid()\n",
      "  (2): Linear(in_features=30, out_features=10, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#Define Model\n",
    "input_size = 28*28\n",
    "internal_layer_size = 30\n",
    "output_size = 10\n",
    "\n",
    "model = nn.Sequential(nn.Linear(input_size,internal_layer_size),nn.Sigmoid(),nn.Linear(internal_layer_size,output_size),nn.Sigmoid())\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MSE LOSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2281, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Loss Function \n",
    "criterion_MSE = nn.MSELoss()\n",
    "images, labels = next(iter(trainloader))\n",
    "images = images.view(images.shape[0], -1)\n",
    "logps = model(images) #log probabilities\n",
    "loss = criterion_MSE(logps, torch.nn.functional.one_hot(labels,num_classes=10).to(torch.float)) #calculate the MSE loss\n",
    "#print(torch.nn.functional.one_hot(labels).to(torch.float))\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backward pass: \n",
      " None\n",
      "After backward pass: \n",
      " tensor([[-0.0002, -0.0002, -0.0002,  ..., -0.0002, -0.0002, -0.0002],\n",
      "        [-0.0016, -0.0016, -0.0016,  ..., -0.0016, -0.0016, -0.0016],\n",
      "        [-0.0016, -0.0016, -0.0016,  ..., -0.0016, -0.0016, -0.0016],\n",
      "        ...,\n",
      "        [ 0.0028,  0.0028,  0.0028,  ...,  0.0028,  0.0028,  0.0028],\n",
      "        [ 0.0004,  0.0004,  0.0004,  ...,  0.0004,  0.0004,  0.0004],\n",
      "        [-0.0004, -0.0004, -0.0004,  ..., -0.0004, -0.0004, -0.0004]])\n"
     ]
    }
   ],
   "source": [
    "#loss function validation\n",
    "print('Before backward pass: \\n', model[0].weight.grad)\n",
    "loss.backward()\n",
    "print('After backward pass: \\n', model[0].weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - Training loss: 0.0885181874036789\n",
      "Epoch 1 - Training loss: 0.08441909402608871\n",
      "Epoch 2 - Training loss: 0.08487170189619064\n",
      "Epoch 3 - Training loss: 0.08864355087280273\n",
      "Epoch 4 - Training loss: 0.042106322944164276\n",
      "Epoch 5 - Training loss: 0.04920416325330734\n",
      "Epoch 6 - Training loss: 0.06486959010362625\n",
      "Epoch 7 - Training loss: 0.048369478434324265\n",
      "Epoch 8 - Training loss: 0.049647461622953415\n",
      "Epoch 9 - Training loss: 0.03962340205907822\n",
      "Epoch 10 - Training loss: 0.06736971437931061\n",
      "Epoch 11 - Training loss: 0.028125038370490074\n",
      "Epoch 12 - Training loss: 0.03456563502550125\n",
      "Epoch 13 - Training loss: 0.03965029492974281\n",
      "Epoch 14 - Training loss: 0.04043184965848923\n",
      "Epoch 15 - Training loss: 0.047869496047496796\n",
      "Epoch 16 - Training loss: 0.006566725671291351\n",
      "Epoch 17 - Training loss: 0.10853858292102814\n",
      "Epoch 18 - Training loss: 0.005426289048045874\n",
      "Epoch 19 - Training loss: 0.0367211177945137\n",
      "\n",
      "Training Time (in minutes) = 2.395744800567627\n"
     ]
    }
   ],
   "source": [
    "#training the model\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(),lr=0.003,momentum=0.9)\n",
    "time0 = time()\n",
    "epochs = 20 \n",
    "\n",
    "for i in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images,labels in trainloader:\n",
    "        images = images.view(images.shape[0],-1)     \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(images)\n",
    "        loss= criterion_MSE(output,torch.nn.functional.one_hot(labels,num_classes=10).to(torch.float))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        print(\"Epoch {} - Training loss: {}\".format(i, loss.item()))  \n",
    "print(\"\\nTraining Time (in minutes) =\",(time()-time0)/60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number Of Images Tested = 9000\n",
      "\n",
      "Validation Model Accuracy with MSE Loss function = 89.54444444444445\n"
     ]
    }
   ],
   "source": [
    "#validation Check\n",
    "correct_count, all_count = 0, 0\n",
    "for images,labels in validationloader:\n",
    "  for i in range(len(labels)):\n",
    "    img = images[i].view(1, 784)\n",
    "    with torch.no_grad():\n",
    "        logps = model(img)\n",
    "    ps = torch.exp(logps)\n",
    "    probab = list(ps.numpy()[0])\n",
    "    pred_label = probab.index(max(probab))\n",
    "    true_label = labels.numpy()[i]\n",
    "    if(true_label == pred_label):\n",
    "      correct_count += 1\n",
    "    all_count += 1\n",
    "\n",
    "print(\"Number Of Images Tested =\", all_count)\n",
    "print(\"\\nValidation Model Accuracy with MSE Loss function =\", 100 * (correct_count/all_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number Of Images Tested = 9000\n",
      "\n",
      "Test Model Accuracy with MSE Loss function= 89.57777777777778\n"
     ]
    }
   ],
   "source": [
    "#Test Check\n",
    "correct_count, all_count = 0, 0\n",
    "for images,labels in Testloader:\n",
    "  for i in range(len(labels)):\n",
    "    img = images[i].view(1, 784)\n",
    "    with torch.no_grad():\n",
    "        logps = model(img)\n",
    "    ps = torch.exp(logps)\n",
    "    probab = list(ps.numpy()[0])\n",
    "    pred_label = probab.index(max(probab))\n",
    "    true_label = labels.numpy()[i]\n",
    "    #print(pred_label,true_label)\n",
    "    if(true_label == pred_label):\n",
    "      correct_count += 1\n",
    "    all_count += 1\n",
    "\n",
    "print(\"Number Of Images Tested =\", all_count)\n",
    "print(\"\\nTest Model Accuracy with MSE Loss function=\", 100 * (correct_count/all_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6959, grad_fn=<DivBackward1>)\n"
     ]
    }
   ],
   "source": [
    "#criterion_CrossEntropy Loss creation\n",
    "criterion_CrossEntropy = nn.CrossEntropyLoss()\n",
    "images, labels = next(iter(trainloader))\n",
    "images = images.view(images.shape[0], -1)\n",
    "logps = model(images) #log probabilities\n",
    "loss = criterion_CrossEntropy(logps, torch.nn.functional.one_hot(labels,num_classes=10).to(torch.float)) #calculate the NLL loss\n",
    "#print(torch.nn.functional.one_hot(labels).to(torch.float))\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backward pass: \n",
      " tensor([[ 1.3571e-03,  1.3571e-03,  1.3571e-03,  ...,  1.3571e-03,\n",
      "          1.3571e-03,  1.3571e-03],\n",
      "        [ 3.3887e-03,  3.3887e-03,  3.3887e-03,  ...,  3.3887e-03,\n",
      "          3.3887e-03,  3.3887e-03],\n",
      "        [ 3.9076e-03,  3.9076e-03,  3.9076e-03,  ...,  3.9076e-03,\n",
      "          3.9076e-03,  3.9076e-03],\n",
      "        ...,\n",
      "        [-5.2860e-06, -5.2860e-06, -5.2860e-06,  ..., -5.2860e-06,\n",
      "         -5.2860e-06, -5.2860e-06],\n",
      "        [-1.9892e-03, -1.9892e-03, -1.9892e-03,  ..., -1.9892e-03,\n",
      "         -1.9892e-03, -1.9892e-03],\n",
      "        [ 1.3975e-04,  1.3975e-04,  1.3975e-04,  ...,  1.3975e-04,\n",
      "          1.3975e-04,  1.3975e-04]])\n",
      "After backward pass: \n",
      " tensor([[-5.7197e-05, -5.7197e-05, -5.7197e-05,  ..., -5.7197e-05,\n",
      "         -5.7197e-05, -5.7197e-05],\n",
      "        [ 7.0909e-03,  7.0909e-03,  7.0909e-03,  ...,  7.0909e-03,\n",
      "          7.0909e-03,  7.0909e-03],\n",
      "        [ 8.6884e-03,  8.6884e-03,  8.6884e-03,  ...,  8.6884e-03,\n",
      "          8.6884e-03,  8.6884e-03],\n",
      "        ...,\n",
      "        [-1.1020e-04, -1.1020e-04, -1.1020e-04,  ..., -1.1020e-04,\n",
      "         -1.1020e-04, -1.1020e-04],\n",
      "        [-9.9236e-04, -9.9236e-04, -9.9236e-04,  ..., -9.9236e-04,\n",
      "         -9.9236e-04, -9.9236e-04],\n",
      "        [-1.5918e-04, -1.5918e-04, -1.5918e-04,  ..., -1.5918e-04,\n",
      "         -1.5918e-04, -1.5918e-04]])\n"
     ]
    }
   ],
   "source": [
    "#Loss validation\n",
    "print('Before backward pass: \\n', model[0].weight.grad)\n",
    "loss.backward()\n",
    "print('After backward pass: \\n', model[0].weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - Training loss: 1.5345172882080078\n",
      "Epoch 1 - Training loss: 1.509224772453308\n",
      "Epoch 2 - Training loss: 1.6433229446411133\n",
      "Epoch 3 - Training loss: 1.4898617267608643\n",
      "Epoch 4 - Training loss: 1.5026359558105469\n",
      "Epoch 5 - Training loss: 1.4859999418258667\n",
      "Epoch 6 - Training loss: 1.482060194015503\n",
      "Epoch 7 - Training loss: 1.5025275945663452\n",
      "Epoch 8 - Training loss: 1.5412571430206299\n",
      "Epoch 9 - Training loss: 1.4823377132415771\n",
      "Epoch 10 - Training loss: 1.7264370918273926\n",
      "Epoch 11 - Training loss: 1.8046472072601318\n",
      "Epoch 12 - Training loss: 1.9749956130981445\n",
      "Epoch 13 - Training loss: 1.4718983173370361\n",
      "Epoch 14 - Training loss: 2.175966262817383\n",
      "Epoch 15 - Training loss: 1.9189342260360718\n",
      "Epoch 16 - Training loss: 1.475761890411377\n",
      "Epoch 17 - Training loss: 1.4820291996002197\n",
      "Epoch 18 - Training loss: 1.5221927165985107\n",
      "Epoch 19 - Training loss: 1.4860000610351562\n",
      "\n",
      "Training Time (in minutes) = 2.684967033068339\n"
     ]
    }
   ],
   "source": [
    "#Training data on Cross Entropy Loss\n",
    "optimizer = optim.SGD(model.parameters(),lr=0.003,momentum=0.9)\n",
    "time0 = time()\n",
    "epochs = 20 \n",
    "\n",
    "for i in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images,labels in trainloader:\n",
    "        images = images.view(images.shape[0],-1)     \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(images)\n",
    "        loss= criterion_CrossEntropy(output,torch.nn.functional.one_hot(labels,num_classes=10).to(torch.float))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        print(\"Epoch {} - Training loss: {}\".format(i, loss.item()))  \n",
    "print(\"\\nTraining Time (in minutes) =\",(time()-time0)/60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number Of Images Tested = 9000\n",
      "\n",
      "Validation Model Accuracy with Cross Entropy Loss= 92.4\n"
     ]
    }
   ],
   "source": [
    "#Validation Check\n",
    "correct_count, all_count = 0, 0\n",
    "for images,labels in validationloader:\n",
    "  for i in range(len(labels)):\n",
    "    img = images[i].view(1, 784)\n",
    "    with torch.no_grad():\n",
    "        logps = model(img)  \n",
    "    ps = torch.exp(logps)\n",
    "    probab = list(ps.numpy()[0])\n",
    "    pred_label = probab.index(max(probab))\n",
    "    true_label = labels.numpy()[i]\n",
    "    if(true_label == pred_label):\n",
    "      correct_count += 1\n",
    "    all_count += 1\n",
    "\n",
    "print(\"Number Of Images Tested =\", all_count)\n",
    "print(\"\\nValidation Model Accuracy with Cross Entropy Loss=\", 100 * (correct_count/all_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number Of Images Tested = 9000\n",
      "\\Test Model Accuracy with Cross Entropy Loss = 92.5111111111111\n"
     ]
    }
   ],
   "source": [
    "#Test Check\n",
    "correct_count, all_count = 0, 0\n",
    "for images,labels in Testloader:\n",
    "  for i in range(len(labels)):\n",
    "    img = images[i].view(1, 784)\n",
    "    with torch.no_grad():\n",
    "        logps = model(img)\n",
    "\n",
    "    \n",
    "    ps = torch.exp(logps)\n",
    "    probab = list(ps.numpy()[0])\n",
    "    pred_label = probab.index(max(probab))\n",
    "    true_label = labels.numpy()[i]\n",
    "    #print(pred_label,true_label)\n",
    "    if(true_label == pred_label):\n",
    "      correct_count += 1\n",
    "    all_count += 1\n",
    "\n",
    "print(\"Number Of Images Tested =\", all_count)\n",
    "print(\"\\Test Model Accuracy with Cross Entropy Loss =\", 100 * (correct_count/all_count))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f06bdd9591808c248588a3d65bfe48fbcb8843ecc0da7a165eb6a1211757627a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
